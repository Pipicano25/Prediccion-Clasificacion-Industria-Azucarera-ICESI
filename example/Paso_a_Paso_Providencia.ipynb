{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64f628ca",
   "metadata": {},
   "source": [
    "\n",
    "# Paso a paso: EDA → Preparación → Modelo (HISTORICO_SUERTES)\n",
    "\n",
    "Este cuaderno te guía con **código paso a paso** desde la exploración hasta el modelo final.  \n",
    "Dataset base: `/mnt/data/HISTORICO_SUERTES.xlsx`  \n",
    "(Integración opcional: `/mnt/data/BD_IPSA_1940.xlsx` si existe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8034799b",
   "metadata": {},
   "source": [
    "## 0) Configuración y librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa7d1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os, warnings, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "DATA_PATH = \"/mnt/data/HISTORICO_SUERTES.xlsx\"\n",
    "DATA_PATH_IPSA = \"/mnt/data/BD_IPSA_1940.xlsx\"  # opcional\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "N_FOLDS = 5\n",
    "SCALER = \"standard\"  # \"standard\" | \"minmax\" | None\n",
    "OUTPUT_DIR = \"outputs_step\"\n",
    "Path(OUTPUT_DIR).mkdir(exist_ok=True, parents=True)\n",
    "print(\"OK configuración\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b3eb50",
   "metadata": {},
   "source": [
    "## 1) Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3958422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert os.path.exists(DATA_PATH), f\"No se encontró el archivo: {DATA_PATH}\"\n",
    "df = pd.read_excel(DATA_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7fa45e",
   "metadata": {},
   "source": [
    "## 2) Panorama general y diccionario inferido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3559886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(df.sample(min(5, len(df))))\n",
    "df.info()\n",
    "display(df.describe(include='all').T)\n",
    "\n",
    "dtypes = df.dtypes.astype(str).rename(\"dtype\")\n",
    "nunique = df.nunique().rename(\"nunique\")\n",
    "n_missing = df.isna().sum().rename(\"n_missing\")\n",
    "pct_missing = (df.isna().mean()*100).round(2).rename(\"%missing\")\n",
    "example = df.head(2).T.iloc[:, :1].rename(columns={df.head(2).columns[0]: \"example\"})\n",
    "data_dict = pd.concat([dtypes, nunique, n_missing, pct_missing, example], axis=1).sort_index()\n",
    "data_dict.to_csv(os.path.join(OUTPUT_DIR, \"data_dictionary.csv\"))\n",
    "display(data_dict.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55765446",
   "metadata": {},
   "source": [
    "## 3) Faltantes y duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103a2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missing_tbl = pd.DataFrame({\"n_missing\": df.isna().sum(), \"%missing\": (df.isna().mean()*100).round(2)}).sort_values(\"%missing\", ascending=False)\n",
    "missing_tbl.to_csv(os.path.join(OUTPUT_DIR, \"missing_summary.csv\"))\n",
    "display(missing_tbl.head(30))\n",
    "\n",
    "dups = df.duplicated().sum()\n",
    "print(\"Duplicados:\", dups)\n",
    "if dups>0:\n",
    "    df = df.drop_duplicates().reset_index(drop=True)\n",
    "    print(\"Eliminados duplicados. Nuevo shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d623f268",
   "metadata": {},
   "source": [
    "## 4) Casting y tratamiento de fechas (heurístico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eaf75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "date_like_cols = [c for c in df.columns if any(x in str(c).lower() for x in [\"f.siembra\",\"siembra\",\"fec.madur\",\"madur\",\"ult.riego\",\"f.ult.corte\",\"fecha\"])]\n",
    "for c in date_like_cols:\n",
    "    df[c] = pd.to_datetime(df[c], errors=\"coerce\", infer_datetime_format=True)\n",
    "print(\"Columnas tratadas como fecha:\", date_like_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f205db4",
   "metadata": {},
   "source": [
    "## 5) Outliers (IQR y Z-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ea38ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def iqr_bounds(s, k=1.5):\n",
    "    q1, q3 = s.quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    return q1 - k*iqr, q3 + k*iqr\n",
    "\n",
    "num_cols_all = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "out_rows = []\n",
    "for c in num_cols_all:\n",
    "    s = df[c].dropna()\n",
    "    if len(s) < 3: \n",
    "        continue\n",
    "    low, up = iqr_bounds(s)\n",
    "    iqr_frac = ((s<low)|(s>up)).mean()\n",
    "    mu, sd = s.mean(), s.std(ddof=0)\n",
    "    z_frac = (sd>0) and ((np.abs((s-mu)/sd)>3).mean()) or 0.0\n",
    "    out_rows.append((c, round(iqr_frac*100,2), round(z_frac*100,2)))\n",
    "out_df = pd.DataFrame(out_rows, columns=[\"col\",\"%outliers_IQR\",\"%outliers_Z>3\"]).sort_values(\"%outliers_IQR\", ascending=False)\n",
    "display(out_df.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509b2182",
   "metadata": {},
   "source": [
    "## 6) Univariado (numérico y categórico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d738cf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Histogramas numéricos (sin estilos ni colores específicos)\n",
    "for c in num_cols_all[:10]:  # muestra hasta 10 para agilidad\n",
    "    plt.figure()\n",
    "    df[c].dropna().hist(bins=30)\n",
    "    plt.title(f\"Histograma: {c}\")\n",
    "    plt.xlabel(c); plt.ylabel(\"Frecuencia\")\n",
    "    plt.show()\n",
    "\n",
    "# Barras categóricas top 20 (si existen)\n",
    "cat_cols_all = df.select_dtypes(include=[\"object\",\"category\",\"bool\"]).columns.tolist()\n",
    "for c in cat_cols_all[:5]:  # muestra hasta 5 para agilidad\n",
    "    plt.figure()\n",
    "    df[c].value_counts(dropna=False).head(20).plot(kind=\"bar\")\n",
    "    plt.title(f\"Frecuencias: {c}\")\n",
    "    plt.xlabel(c); plt.ylabel(\"Conteo\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efcb152",
   "metadata": {},
   "source": [
    "## 7) Correlaciones con objetivos (TCH y sacarosa/%Sac.Caña si existen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630f8525",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TARGET_CANDIDATES = [\"TCH\", \"%Sac.Caña\", \"%Sac.Cana\", \"% Sac.Caña\", \"sacarosa\"]\n",
    "present_targets = [t for t in TARGET_CANDIDATES if t in df.columns]\n",
    "print(\"Objetivos detectados:\", present_targets)\n",
    "\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "for tgt in present_targets:\n",
    "    cols = [c for c in num_cols if c != tgt]\n",
    "    if cols:\n",
    "        corr = df[[tgt] + cols].corr(numeric_only=True)[tgt].sort_values(ascending=False)\n",
    "        display(pd.DataFrame(corr).rename(columns={tgt:\"corr\"}).head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627441a6",
   "metadata": {},
   "source": [
    "## 8) Ingeniería de variables derivadas (duraciones y densidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c0c6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_feat = df.copy()\n",
    "\n",
    "# Duraciones desde fechas (en días)\n",
    "col_siembra = next((c for c in df_feat.columns if \"siembra\" in str(c).lower()), None)\n",
    "col_ult_corte = next((c for c in df_feat.columns if \"ult.corte\" in str(c).lower()), None)\n",
    "col_ult_riego = next((c for c in df_feat.columns if \"ult.riego\" in str(c).lower()), None)\n",
    "col_madur = next((c for c in df_feat.columns if \"madur\" in str(c).lower()), None)\n",
    "\n",
    "if col_siembra and col_ult_corte:\n",
    "    df_feat[\"feat_dias_siembra_a_ultcorte\"] = (df_feat[col_ult_corte] - df_feat[col_siembra]).dt.days\n",
    "if col_siembra and col_madur:\n",
    "    df_feat[\"feat_dias_siembra_a_madur\"] = (df_feat[col_madur] - df_feat[col_siembra]).dt.days\n",
    "if col_ult_riego and col_ult_corte:\n",
    "    df_feat[\"feat_dias_ult_riego_a_ultcorte\"] = (df_feat[col_ult_corte] - df_feat[col_ult_riego]).dt.days\n",
    "\n",
    "# TCH/Área si ambas existen\n",
    "col_area = next((c for c in df_feat.columns if \"area neta\" in str(c).lower() or \"área neta\" in str(c).lower()), None)\n",
    "if col_area and \"TCH\" in df_feat.columns:\n",
    "    safe_area = df_feat[col_area].replace({0: np.nan})\n",
    "    df_feat[\"feat_tch_por_area\"] = df_feat[\"TCH\"] / safe_area\n",
    "\n",
    "# Semanas maduración (si existe)\n",
    "col_sem_mad = next((c for c in df_feat.columns if \"semanas\" in str(c).lower() and \"mad\" in str(c).lower()), None)\n",
    "if col_sem_mad:\n",
    "    df_feat[\"feat_sem_mad\"] = pd.to_numeric(df_feat[col_sem_mad], errors=\"coerce\")\n",
    "\n",
    "[c for c in df_feat.columns if c.startswith(\"feat_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff2974e",
   "metadata": {},
   "source": [
    "## 9) Preparación: train/test y ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d13f247",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_preprocess(X, scaler_kind=\"standard\"):\n",
    "    num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    cat_cols = X.select_dtypes(include=[\"object\",\"category\",\"bool\"]).columns.tolist()\n",
    "\n",
    "    if scaler_kind == \"standard\":\n",
    "        scaler = StandardScaler()\n",
    "    elif scaler_kind == \"minmax\":\n",
    "        scaler = MinMaxScaler()\n",
    "    else:\n",
    "        scaler = None\n",
    "\n",
    "    num_steps = [(\"imputer\", SimpleImputer(strategy=\"median\"))]\n",
    "    if scaler is not None:\n",
    "        num_steps.append((\"scaler\", scaler))\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=num_steps)\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, num_cols),\n",
    "            (\"cat\", categorical_transformer, cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "        verbose_feature_names_out=False\n",
    "    )\n",
    "    return preprocess\n",
    "\n",
    "targets_present = present_targets if present_targets else [\"TCH\"]  # fallback si sólo hay TCH\n",
    "targets_present"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a95b6a",
   "metadata": {},
   "source": [
    "## 10) Modelado por objetivo — OLS, Ridge, Lasso, KNN, Árbol, RandomForest y Polinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812d800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_results = {}\n",
    "for target in targets_present:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Objetivo:\", target)\n",
    "    print(\"=\"*70)\n",
    "    X = df_feat.drop(columns=[target], errors=\"ignore\")\n",
    "    y = df_feat[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "    preprocess = build_preprocess(X_train, scaler_kind=SCALER)\n",
    "\n",
    "    def eval_model(model, name):\n",
    "        pipe = Pipeline([(\"prep\", preprocess), (\"model\", model)])\n",
    "        cv = KFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        cv_rmse = -cross_val_score(pipe, X_train, y_train, cv=cv, scoring=\"neg_root_mean_squared_error\")\n",
    "        pipe.fit(X_train, y_train)\n",
    "        preds = pipe.predict(X_test)\n",
    "        metrics = {\n",
    "            \"MAE\": mean_absolute_error(y_test, preds),\n",
    "            \"RMSE\": mean_squared_error(y_test, preds, squared=False),\n",
    "            \"R2\": r2_score(y_test, preds),\n",
    "            \"cv_RMSE_mean\": cv_rmse.mean(),\n",
    "            \"cv_RMSE_std\": cv_rmse.std()\n",
    "        }\n",
    "        print(f\"\\n— {name} —\")\n",
    "        display(pd.Series(metrics))\n",
    "        plt.figure()\n",
    "        plt.scatter(y_test, preds, alpha=0.6)\n",
    "        lims = [min(np.min(y_test), np.min(preds)), max(np.max(y_test), np.max(preds))]\n",
    "        plt.plot(lims, lims, \"--\")\n",
    "        plt.xlabel(\"Real\"); plt.ylabel(\"Predicho\"); plt.title(f\"Real vs Predicho — {name}\")\n",
    "        plt.show()\n",
    "        return pipe, metrics\n",
    "\n",
    "    results = {}\n",
    "    fitted = {}\n",
    "\n",
    "    models = [\n",
    "        (LinearRegression(), \"OLS\"),\n",
    "        (Ridge(alpha=1.0, random_state=RANDOM_STATE), \"Ridge(alpha=1)\"),\n",
    "        (Lasso(alpha=0.001, random_state=RANDOM_STATE, max_iter=10000), \"Lasso(alpha=0.001)\"),\n",
    "        (KNeighborsRegressor(n_neighbors=5), \"KNNReg(k=5)\"),\n",
    "        (DecisionTreeRegressor(random_state=RANDOM_STATE), \"DecisionTreeReg\"),\n",
    "        (RandomForestRegressor(n_estimators=300, random_state=RANDOM_STATE), \"RandomForestReg\"),\n",
    "    ]\n",
    "    for m, name in models:\n",
    "        p, met = eval_model(m, name)\n",
    "        results[name] = met\n",
    "        fitted[name] = p\n",
    "\n",
    "    # Polinomial (grado 2)\n",
    "    poly_pipe = Pipeline([(\"prep\", preprocess),\n",
    "                          (\"poly\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "                          (\"model\", LinearRegression())])\n",
    "    cv = KFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    rmse_cv = -cross_val_score(poly_pipe, X_train, y_train, cv=cv, scoring=\"neg_root_mean_squared_error\")\n",
    "    poly_pipe.fit(X_train, y_train)\n",
    "    preds = poly_pipe.predict(X_test)\n",
    "    metrics_poly = {\n",
    "        \"MAE\": mean_absolute_error(y_test, preds),\n",
    "        \"RMSE\": mean_squared_error(y_test, preds, squared=False),\n",
    "        \"R2\": r2_score(y_test, preds),\n",
    "        \"cv_RMSE_mean\": rmse_cv.mean(),\n",
    "        \"cv_RMSE_std\": rmse_cv.std()\n",
    "    }\n",
    "    print(\"\\n— Polynomial(2) —\")\n",
    "    display(pd.Series(metrics_poly))\n",
    "    results[\"Polynomial2\"] = metrics_poly\n",
    "    fitted[\"Polynomial2\"] = poly_pipe\n",
    "\n",
    "    res_df = pd.DataFrame(results).T.sort_values(\"RMSE\", ascending=True)\n",
    "    display(res_df)\n",
    "    all_results[target] = res_df\n",
    "\n",
    "    # Exportar mejor\n",
    "    best_name = res_df.index[0]\n",
    "    joblib.dump(fitted[best_name], os.path.join(OUTPUT_DIR, f\"best_pipeline_{target}_{best_name}.joblib\"))\n",
    "    with open(os.path.join(OUTPUT_DIR, f\"metrics_{target}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({k:{kk:float(vv) for kk,vv in d.items()} for k,d in results.items()}, f, indent=2)\n",
    "\n",
    "print(\"Artefactos guardados en:\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5bc30e",
   "metadata": {},
   "source": [
    "## 11) (Opcional) GridSearch y curvas de aprendizaje para el mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d46ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for target, res_df in all_results.items():\n",
    "    print(\"\\n\", \"#\"*20, target, \"#\"*20)\n",
    "    best_name = res_df.index[0]\n",
    "    print(\"Mejor por RMSE:\", best_name)\n",
    "    # Ejemplo: tunear RF si fue el mejor\n",
    "    if \"RandomForestReg\" in best_name:\n",
    "        X = df_feat.drop(columns=[target], errors=\"ignore\"); y = df_feat[target]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "        preprocess = build_preprocess(X_train, scaler_kind=SCALER)\n",
    "        base = Pipeline([(\"prep\", preprocess), (\"model\", RandomForestRegressor(random_state=RANDOM_STATE))])\n",
    "        grid = GridSearchCV(\n",
    "            base,\n",
    "            param_grid={\"model__n_estimators\":[200,400], \"model__max_depth\":[None, 10, 20]},\n",
    "            scoring=\"neg_root_mean_squared_error\",\n",
    "            cv=KFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE),\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        grid.fit(X_train, y_train)\n",
    "        print(\"Best params:\", grid.best_params_)\n",
    "        print(\"Best CV RMSE:\", (-grid.best_score_)**0.5 if grid.best_score_<0 else -grid.best_score_)\n",
    "\n",
    "        # Curva de aprendizaje\n",
    "        train_sizes, train_scores, test_scores = learning_curve(\n",
    "            grid.best_estimator_, X, y, cv=N_FOLDS,\n",
    "            scoring=\"neg_root_mean_squared_error\",\n",
    "            n_jobs=-1, train_sizes=np.linspace(0.1,1.0,5), shuffle=True, random_state=RANDOM_STATE\n",
    "        )\n",
    "        tr = -train_scores.mean(axis=1)\n",
    "        te = -test_scores.mean(axis=1)\n",
    "        plt.figure()\n",
    "        plt.plot(train_sizes, tr, marker=\"o\", label=\"train RMSE\")\n",
    "        plt.plot(train_sizes, te, marker=\"s\", label=\"cv RMSE\")\n",
    "        plt.xlabel(\"Tamaño de entrenamiento\"); plt.ylabel(\"RMSE\")\n",
    "        plt.title(f\"Curva de aprendizaje — {target}\")\n",
    "        plt.legend(); plt.grid(True); plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
